host: selva
Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 64
Rules claiming more threads will be scaled down.
Job stats:
job          count
---------  -------
map_reads        1
total            1

Select jobs to execute...
Execute 1 jobs...

[Tue May 20 11:45:00 2025]
localrule map_reads:
    input: /home/hamzaamhal/snakemake_pipline2/scripts/02_mapping.sh
    output: /home/hamzaamhal/snakemake_pipline2/output/mapping_done.txt
    jobid: 0
    reason: Missing output files: /home/hamzaamhal/snakemake_pipline2/output/mapping_done.txt
    resources: tmpdir=/tmp

[Tue May 20 11:45:00 2025]
Error in rule map_reads:
    jobid: 0
    input: /home/hamzaamhal/snakemake_pipline2/scripts/02_mapping.sh
    output: /home/hamzaamhal/snakemake_pipline2/output/mapping_done.txt
    shell:
        
        bash /home/hamzaamhal/snakemake_pipline2/scripts/02_mapping.sh > /home/hamzaamhal/snakemake_pipline2/logfile/mapping_output.log 2>&1
        touch /home/hamzaamhal/snakemake_pipline2/output/mapping_done.txt
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2025-05-20T114500.415411.snakemake.log
WorkflowError:
At least one job did not complete successfully.
